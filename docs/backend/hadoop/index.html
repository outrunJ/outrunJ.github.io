<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Hadoop"><meta property="og:title" content="" />
<meta property="og:description" content="介绍 大数据 PB级数据 4V volume(大量) velocity(高速) variety(多样) value(低价值密度) 场景 物流仓储: 精细化运营，命中率 推荐 保险: 风险预测 金融: 用户特征 房产: 精准投策、营销 AI 组织部门 平台: 集群 Hadoop、Flume、Kafka、HBase、Spark等搭建 性能监控、调优 数据仓库: 写SQL ETL, 数据清洗 Hive, 数据分析、建模 数据挖掘 数据支持 算法、推荐、用户画像 报表 JavaEE hadoop Apache开源, 分布式系统基础架构 面临问题 硬盘 1块: 10TB-14TB 1PB: 102块硬盘 算 MySQL5.5: 300w-500w MySQL8: 1亿、1GB Doug Cutting GFS -&gt; HDFS 存储 Map-Reduce -&gt; MapReduce 计算 BigTable -&gt; HBase 表式存储 发展 2003-2004: Google公开部分GFS和MapReduce 2005: Hadoop成为Apache Lucene子项目Nutch了一部分 2006.3: MapReduce和NDFS(Nutch Distributed File System)纳入Hadoop 发行版本 Apache: 开源 Cloudera: Doug Cutting, 一键部署, 资源占用大 Hortonworks: 雅虎工程师，贡献Hadoop 80%代码, 一键部署 阿里云 特点 高可靠性：多副本 高扩展性 高效性: 并行运行 高容错性 组成 Hadoop1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://example.com/docs/backend/hadoop/" />

<title>Hadoop | outrun的笔记</title>
<link rel="icon" href="/favicon.png" type="image/x-icon">


<link rel="stylesheet" href="/book.min.eddc90f1d1267cb826e7cffc53c434e50061c4bfe41146a43670842ce6cb3bf6.css" integrity="sha256-7dyQ8dEmfLgm58/8U8Q05QBhxL/kEUakNnCELObLO/Y=">


<script defer src="/en.search.min.89e277eaffc2d6dc705b9a49befe5b401408d8ab0d73322c720731b5efe7dd95.js" integrity="sha256-ieJ36v/C1txwW5pJvv5bQBQI2KsNczIscgcxte/n3ZU="></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-154152836-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body>
  <input type="checkbox" class="hidden" id="menu-control" />
  <main class="flex container">

    <aside class="book-menu fixed">
      <nav>
<h2 class="book-brand">
  <a href="https://example.com/"><img src="/logo.png" alt="Logo" /><span>outrun的笔记</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" />
  <div class="book-search-spinner spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>





    <ul>
<li><a href="/"><strong>介绍</strong></a></li>
<li><a href="/docs/algorithm"><strong>算法</strong></a>
<ul>
<li><a href="/docs/algorithm/math">数学</a></li>
<li><a href="/docs/algorithm/thought">思想</a></li>
<li><a href="/docs/algorithm/data_structure">数据结构</a></li>
</ul>
</li>
<li><a href="/docs/design"><strong>设计</strong></a>
<ul>
<li><a href="/docs/design/drive">驱动</a></li>
<li><a href="/docs/design/biz">行业</a></li>
<li><a href="/docs/design/organize">组织</a></li>
<li><a href="/docs/design/people">人员</a></li>
<li><a href="/docs/design/project">工程</a></li>
<li><a href="/docs/design/code">代码</a></li>
</ul>
</li>
<li><a href="/docs/pl"><strong>程序语言</strong></a>
<ul>
<li><a href="/docs/pl/principle">原理</a></li>
<li><a href="/docs/pl/go">go</a></li>
<li><a href="/docs/pl/js">js</a></li>
<li><a href="/docs/pl/java">java</a></li>
<li><a href="/docs/pl/python">python</a></li>
<li><a href="/docs/pl/haskell">haskell</a></li>
<li><a href="/docs/pl/clojure">clojure</a></li>
<li><a href="/docs/pl/markup_language"><em><strong>标记语言</strong></em></a>
<ul>
<li><a href="/docs/pl/markup_language/html">html</a></li>
<li><a href="/docs/pl/markup_language/css">css</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/docs/architecture"><strong>架构</strong></a>
<ul>
<li><a href="/docs/architecture/principle">原理</a></li>
<li><a href="/docs/architecture/performance">性能</a></li>
<li><a href="/docs/architecture/solution">方案</a></li>
<li><a href="/docs/architecture/nginx">nginx</a></li>
<li><a href="/docs/architecture/nodejs">nodejs</a></li>
<li><a href="/docs/architecture/spring_cloud">spring cloud</a></li>
</ul>
</li>
<li><a href="/docs/backend"><strong>后端</strong></a>
<ul>
<li><a href="/docs/backend/principle">原理</a></li>
<li><a href="/docs/backend/elasticsearch">elasticsearch</a></li>
<li><a href="/docs/backend/javaweb">javaweb</a></li>
<li><a href="/docs/backend/spring">spring</a></li>
<li><a href="/docs/backend/hibernate">hibernate</a></li>
<li><a href="/docs/backend/hadoop">hadoop</a></li>
</ul>
</li>
<li><a href="/docs/db"><strong>数据库</strong></a>
<ul>
<li><a href="/docs/db/mongodb">mongodb</a></li>
<li><a href="/docs/db/mysql">mysql</a></li>
<li><a href="/docs/db/oracle">oracle</a></li>
<li><a href="/docs/db/postgre_sql">pgsql</a></li>
<li><a href="/docs/db/redis">redis</a></li>
</ul>
</li>
<li><a href="/docs/frontend"><strong>前端</strong></a>
<ul>
<li><a href="/docs/frontend/jquery">jquery</a></li>
<li><a href="/docs/frontend/bootstrap">bootstrap</a></li>
<li><a href="/docs/frontend/angular">angular</a></li>
<li><a href="/docs/frontend/react">react</a></li>
<li><a href="/docs/frontend/threejs">three.js</a></li>
</ul>
</li>
<li><a href="/docs/ops"><strong>运维</strong></a>
<ul>
<li><a href="/docs/ops/linux">linux</a></li>
<li><a href="/docs/ops/tool">工具</a></li>
<li><a href="/docs/ops/security">安全</a></li>
<li><a href="/docs/ops/docker">docker</a></li>
</ul>
</li>
<li><a href="/docs/test"><strong>测试</strong></a></li>
<li><a href="/docs/tool"><strong>图形工具</strong></a>
<ul>
<li><a href="/docs/tool/vim">vim</a></li>
<li><a href="/docs/tool/eclipse">eclipse</a></li>
<li><a href="/docs/tool/apple">apple</a></li>
</ul>
</li>
<li><a href="/docs/misc"><strong>misc</strong></a>
<ul>
<li><a href="/docs/misc/infomation">信息</a></li>
<li><a href="/docs/misc/media">媒体</a></li>
<li><a href="/docs/misc/english">英语</a></li>
<li><a href="/docs/misc/interview">题目</a></li>
</ul>
</li>
<li><a href="/docs/cache"><strong>cache</strong></a>
<ul>
<li><a href="/docs/cache/device">设备</a></li>
<li><a href="/docs/cache/app">app</a></li>
<li><a href="/docs/cache/develop">开发</a></li>
<li><a href="/docs/cache/ops">运维</a></li>
</ul>
</li>
<li><a href="/posts"><strong>博客</strong></a></li>
<li><a href="/about_me">关于我</a></li>
</ul>





</nav>


<script>
(function() {
  var menu = document.querySelector("aside.book-menu nav");
  addEventListener("beforeunload", function(event) {
    localStorage.setItem("menu.scrollTop", menu.scrollTop);
  });
  menu.scrollTop = localStorage.getItem("menu.scrollTop");
})();
</script>

    </aside>

    <div class="book-page">
      <header class="flex align-center justify-between book-header">
  <label for="menu-control">
    <img src="/svg/menu.svg" alt="Menu" />
  </label>
  <strong>Hadoop</strong>
</header>

      
<article class="markdown"><h1 id="heading">介绍</h1>
<pre><code>大数据 
    PB级数据
    4V
        volume(大量)
        velocity(高速)
        variety(多样)
        value(低价值密度)
    场景
        物流仓储: 精细化运营，命中率
        推荐
        保险: 风险预测
        金融: 用户特征
        房产: 精准投策、营销
        AI
    组织部门
        平台: 集群
            Hadoop、Flume、Kafka、HBase、Spark等搭建
            性能监控、调优
        数据仓库: 写SQL
            ETL, 数据清洗
            Hive, 数据分析、建模
        数据挖掘
            数据支持
            算法、推荐、用户画像
        报表
            JavaEE
hadoop
    Apache开源, 分布式系统基础架构
    面临问题
        硬盘
            1块: 10TB-14TB 
            1PB: 102块硬盘
        算
            MySQL5.5: 300w-500w
            MySQL8: 1亿、1GB
    Doug Cutting
        GFS -&gt; HDFS
            存储
        Map-Reduce -&gt; MapReduce
            计算
        BigTable -&gt; HBase
            表式存储
    发展
        2003-2004: Google公开部分GFS和MapReduce
        2005: Hadoop成为Apache Lucene子项目Nutch了一部分
        2006.3: MapReduce和NDFS(Nutch Distributed File System)纳入Hadoop
    发行版本
        Apache: 开源
        Cloudera: Doug Cutting, 一键部署, 资源占用大
        Hortonworks: 雅虎工程师，贡献Hadoop 80%代码, 一键部署
        阿里云
    特点
        高可靠性：多副本
        高扩展性
        高效性: 并行运行
        高容错性
    组成
        Hadoop1.x
            HDFS(存), MapReduce(算、资源调度), Common
        Hadoop2.x
            HDFS(存), MapReduce(算), Yarn(资源调度), Common
        Hadoop3.x
</code></pre>
<h1 id="heading-1">流程</h1>
<pre><code>数据
</code></pre>
<table>
<thead>
<tr>
<th align="left">来源</th>
<th align="left">结构化数据: 数据库</th>
<th align="left">半结构化数据: 文件日志</th>
<th align="left">非结构化数据: 视频, PPT</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">传输</td>
<td align="left">Sqoop</td>
<td align="left">Flume</td>
<td align="left">Kafka</td>
</tr>
<tr>
<td align="left">存储</td>
<td align="left">HDFS, HBase</td>
<td align="left">HDFS, HBase</td>
<td align="left">Kafka</td>
</tr>
<tr>
<td align="left">管理</td>
<td align="left">YARN</td>
<td align="left">YARN</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">计算</td>
<td align="left">MapReduce</td>
<td align="left">MapReduce</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">包装</td>
<td align="left">Hive, Mahout</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">任务调度</td>
<td align="left">Oozie, Azkaban</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left">业务模型</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<pre><code>计算
    MapReduce(离线)
        Hive(查询)
        Mahout(数据挖掘)
    SparkCore(内存)
        Mahout(数据挖掘)
        Spark Mlib(数据挖掘): 用户画像, 产品聚类
        Spark R(数据分析)
        Spark SQL(数据查询)
        Spark Streaming(实时/在线/流式)
            有缓存
    Storm(实时)
        # 口径小, 被淘汰
        纯流式计算(无缓存)
    Flink(实时)
        纯流式计算(无缓存)
调度
    介绍：处理任务依赖
支撑/发现
    Zookeeper    
</code></pre>
<h1 id="heading-2">组件</h1>
<pre><code>论文
    BigTable
转换
    Pig
        # 数据流处理, 脚本转换为MapReduce任务
    Sqoop
        # etl, sql-to-Hadoop, MapReduce程序, 支持Hive, HDFS
    kafka
数据
    HDFS
        介绍
            Hadoop Distributed File System, 分布式文件系统, 一开始为Nutch搜索引擎开发
        优点
            高容错, 高吞吐量
            部署在廉价机器上
        模块
            NameNode(nn)
                存metadata: 文件名, 目录结构(生成时间、副本数、文件权限), 文件块列表，文件块所在DataNode
            DataNode(dn)
                本地FS, 存文件块，文件块校验和
                数据在dataNode间水平传递
            Secondary NameNode(2nn)
                监控HDFS，周期获取HDFS元数据快照
                可恢复部分NameNode
        结构
            metadata
                /test/a.log, 3, {blk_1,blk_2}, [{blk_1:[h0,h1,h3]},{blk_2:[h0,h2,h4]}]
        命令
            hdfs
    Hbase
        介绍
            Hadoop Database, 实时分布式, bigtable列簇数据库, 非结构化，自动切分, 并发读写
        缺点
            只能row key查询, master单点
    Hive
        # 数据仓库, 映射成表, sql MapReduce, 批处理
    Impala
        # cloudrea开源,实时视图计算框架, 分布式查询引擎。直接从HDFS或Hbase中用select, join, 支持事务, 需要kafka
    GFS
        # google FS
    TiDB
计算
    在线
        Storm
            介绍
                实时视图计算框架, 支持事务, 需要kafka
        S4
            # 分布式流计算，允许请求丢失
    离线
        MapReduce
            阶段
                Map: 切分，并行计算
                Reduce: 从map中取多个计算结果，进行合并
            命令
                hadoop jar a.jar grep input output 'dfs[a-z.]+'
        Mahout
            # 数据挖掘, 机器学习
        Spark
            介绍 
                分布式计算, scala实现, 建立在HDFS上,也可Hadoop 基于内存的分布式数据集(rdd), 准实时
            缺点
                无事务
            组件
                Spark RDD(Resiliennt Distributed Datasets)
                Spark Streaming
                Spark SQL
    查询
        HAWQ
            # Hadoop原生sql查询引擎
        phoenix
            # OLTP, 支持Hbase和HDFS, jdbc, 更快sql查询
        Shark
            # sql on Spark, 并行job处理比MapReduce快100倍
        Presto
            # 分布式sql查询, facebook开源, 称比Hive快10倍
        Drill
            # Apache, Dremel的开源版本, 对多数据库生成query plan
        Dremel
            介绍
                google的交互式数据分析系统，构建于gfs上
            特点
                嵌套型数据的列存储, 多层查询
                减少查询的处理数据量
        Kylin
            # OLAP, Apache, 支持Cube类查询
调度
    K8S
    Yarn
        介绍
            Yet Another Resource Negotiator, 调度算力资源, 在HDFS上运行计算框架(如MapReduce, Storm, Spark)
        组成
            ResourceManager(RM)
                处理请求
                监控NodeManager
                启动、监控ApplicationMaster
                资源分配调度
                常驻
            NodeManager(NM)
                常驻
            ApplicationMaster(AM)
                数据切分
                为应用程序申请资源再分配给内部任务
                任务监控、容错
                非常驻，job拉起
            Container
                运行APP
                某节点上多维度的资源
                由NodeManager调度
                非常驻
    Mesos
治理
    Zookeeper
    Flume
        # cloudera开源, 日志收集
    Ganglia
        分布式监控系统，php页面
集成
    Ambari
        # 安装、部署、配置和管理
        组件
            Log Search
发行版
    Apache Hadoop
    CDH(Cloudera's Distribution Including Apache Hadoop)
    HDP(Hortonworks Data Platform)
ui
    HUE
        # web管理Hadoop
搜索
    ElasticSearch
    Solr
方案
    宜信
        D.Bus
            # 数据收集与计算
        UAVStack
            # AIOps, 智能运维
            UAV.Monitor
                # 监控
            UAV.APM
                # 性能管理
            UAV.ServiceGovern
                # 服务治理
            UAV.MSCP
                # 微服务计算
        Wormhole
            # SPaaS(Stream Processing as a Service)
        Gartner
            # ITOA，算法即运维
</code></pre>
<h1 id="heading-3">部署</h1>
<pre><code>本地模式
伪分布模式(学习用)
集群模式
例子
    软件结构
        0        jdk, Hadoop                        NameNode, DFSZKFailoverController
        1        jdk, Hadoop                        NameNode, DFSZKFailoverController
        2        jdk, Hadoop                        ResourceManager
        3        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
        4        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
        5        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
    Zookeeper
        配置conf/zoo.cfg
            tickTime=2000                        # 心跳间隔(ms)
            initLimit=10                        # 初始化时最多容忍心跳次数
            syncLimit=5                        # 同步失败最多容忍心跳次数
            dataDir=/usr/local/Zookeeper/data        # 运行时文件目录
            clientPort=2181                # 运行端口号
            server.1=主机名或ip:2888:3888        # 服务运行端口与选举端口
            server.2=主机名或ip:2888:3888
            server.3=主机名或ip:2888:3888
        命令
            ./bin/zkServer.sh start
            ./bin/zkServer.sh status
            jps                                        # 显示名为QuorumPeerMain
    Hadoop
        Hadoop-env.sh
            export JAVA_HOME=
        core-site.xml
            &lt;configuration&gt;
                &lt;property&gt;
                    &lt;name&gt;fs.defaultFS&lt;/name&gt;
                    &lt;value&gt;HDFS://ns1&lt;/value&gt;
                &lt;/property&gt;
                &lt;property&gt;
                    &lt;name&gt;Hadoop.tmp.dir&lt;/name&gt;
                    &lt;value&gt;/usr/local/Hadoop-2.2.0/tmp&lt;/value&gt;
                &lt;/property&gt;
                &lt;property&gt;
                    &lt;name&gt;ha.Zookeeper.quorum&lt;/name&gt;
                    &lt;value&gt;192.168.56.13:2181, 192.168.56.14:2181, 192.168.56.15:2181&lt;/value&gt;
                &lt;/property&gt;
            &lt;/configuration&gt;
        HDFS-site.xml
            &lt;property&gt;
                &lt;name&gt;dfs.nameservices&lt;/name&gt;
                &lt;value&gt;ns1&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;
                &lt;value&gt;nn1,nn2&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;
                &lt;value&gt;192.168.56.10:9000&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;
                &lt;value&gt;192.168.56.10:50070&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;
                &lt;value&gt;192.168.56.11:9000&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;
                &lt;value&gt;192.168.56.11:50070&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
                &lt;value&gt;qjournal://192.168.56.13:8485;192.168.56.14:8485;192.168.56.15:8485&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
                &lt;value&gt;/usr/local/Hadoop-2.2.0/journal&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
                &lt;value&gt;true&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;
                &lt;value&gt;org.Apache.Hadoop.HDFS.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
                &lt;value&gt;sshfence&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
                &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
            &lt;/property&gt;
        mapred-site.xml
            &lt;property&gt;
                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
                &lt;value&gt;Yarn&lt;/value&gt;
            &lt;/property&gt;
        Yarn-site.xml
            &lt;property&gt;
                &lt;name&gt;Yarn.resourcemanager.hostname&lt;/name&gt;
                &lt;value&gt;192.168.56.12&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;Yarn.nodemanager.aux-services&lt;/name&gt;
                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
            &lt;/property&gt;
        etc/Hadoop/slaves
            192.168.56.13
            192.168.56.14
            192.168.56.15
    收尾
        o-&gt; ssh免登录(0到1,2,3,4,5)
            ssh-keygen -t rsa
            ssh-copy-id -i 192.168.56.11            # 这样就可以免登录访问192.168.56.11了
                                                    ## ssh-copy-id -i localhost 免登录自己

        o-&gt; 复制Hadoop2.2.0(从0到1,2,3,4,5)

        o-&gt; 添加Hadoop_home到环境变量
            etc/profile
                export HADOOP_HOME=/usr/local/Hadoop-2.2.0
                export PATH=$PATH:$HADOOP_HOME/bin
    启动
        0 上启动
            ./sbin/Hadoop-daemons.sh start journalnode
        0 上格式化namenode
            Hadoop namenode -format
</code></pre>
</article>

      <div class="book-footer justify-between">
  

  
  
  <div>
    
    <a class="flex align-center" href="https://github.com/outrunJ/hugo-blog/commit/adc0cf7ce98f30a58eff2eafe7af92f6382f0df9" title='Last modified by shenwenqing | Feb 7, 2020' target="_blank">
      <img src="/svg/calendar.svg" alt="Calendar" />
      <span>Feb 7, 2020</span>
    </a>
  </div>
  
  

  
  <div>
    <a class="flex align-center" href="https://github.com/outrunJ/hugo-blog/tree/master/content/docs/backend/hadoop.md" target="_blank">
      <img src="/svg/edit.svg" alt="Edit" />
      <span>Edit this page</span>
    </a>
  </div>
  

</div>

      
    </div>

    
  

  <aside class="book-toc levels-6 fixed">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#heading">介绍</a></li>
    <li><a href="#heading-1">流程</a></li>
    <li><a href="#heading-2">组件</a></li>
    <li><a href="#heading-3">部署</a></li>
  </ul>
</nav>
  </aside>



  </main>

  
</body>

</html>
