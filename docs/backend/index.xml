<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>后端 on outrun的笔记</title>
    <link>https://example.com/docs/backend/</link>
    <description>Recent content in 后端 on outrun的笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 10 Oct 2018 14:36:50 +0800</lastBuildDate>
    
	<atom:link href="https://example.com/docs/backend/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Mybatis</title>
      <link>https://example.com/docs/backend/mybatis/</link>
      <pubDate>Thu, 11 Oct 2018 15:09:36 +0800</pubDate>
      
      <guid>https://example.com/docs/backend/mybatis/</guid>
      <description>使用 1.导入ibatis jar包 2.配置文件 SqlMap.properties # 属性名可以修改 driver=oracle.jdbc.driver.OracleDriver url=jdbc:oracle:thin:@127.0.0.1:1521:orcl username=root password=root SqlMapConfig.xml # 总配置文件 &amp;lt;sqlMapConfig&amp;gt; &amp;lt;properties recource=&amp;quot;SqlMap.properties&amp;quot;/&amp;gt; &amp;lt;transactionManager type=&amp;quot;JDBC&amp;quot;&amp;gt; &amp;lt;dataSource type=&amp;quot;SIMPLE&amp;quot;&amp;gt; &amp;lt;property value=&amp;quot;${driver}&amp;quot; name=&amp;quot;JDBC.Driver&amp;quot;/&amp;gt; &amp;lt;property value=&amp;quot;${url}&amp;quot; name=&amp;quot;JDBC.ConnectionURL&amp;quot;/&amp;gt; &amp;lt;property value=&amp;quot;${username}&amp;quot; name=&amp;quot;JDBC.Username&amp;quot;/&amp;gt; &amp;lt;property value=&amp;quot;${password}&amp;quot; name=&amp;quot;JDBC.Password&amp;quot;/&amp;gt; &amp;lt;sqlMap resource=&amp;quot;Student.xml&amp;quot;/&amp;gt; Student.xml # 映射xml文件 &amp;lt;sqlMap&amp;gt; &amp;lt;typeAlias alias=&amp;quot;Student&amp;quot; type=&amp;quot;com.Student&amp;quot;/&amp;gt; &amp;lt;select id=&amp;quot;selectAllStudent&amp;quot; resultClass=&amp;quot;Student&amp;quot;&amp;gt; select * from Student 辅助类Student.java # 要求有无参构造方法 private sid = 0; private String name = null; private String major = null; private Date birth = null; private float score = 0; 3.</description>
    </item>
    
    <item>
      <title>Struts2</title>
      <link>https://example.com/docs/backend/struts2/</link>
      <pubDate>Thu, 11 Oct 2018 14:49:08 +0800</pubDate>
      
      <guid>https://example.com/docs/backend/struts2/</guid>
      <description>介绍 就是一个利用filter拦截所有请求，利用反射转发请求与响应数据的过滤器。它通过配置文件来设置请求地址与处理类之间的数据流转 struts2中处理请求的类（Action类）是非单例的，所以效率比较低  思想 Action类中的无侵入设计（新技术中不出现旧技术）：map代替了作用域 ActionContext actionContext = actionContext.getContext() actionContext.getApplication() actionContext.getSession() 好处 map是java中的api，不出现旧技术 测试方便（ servlet不能测试，只能发布测试） # 注意：Action类中用到作用域map的方法也不能测试  结构 apps: 例子程序 docs:帮助文件 lib:程序包 src:源码  使用 要求 jdk5 jsp2 servlet api2.4 1.导入核心的8个包 struts2-core-2.3.1.1.jar # struts的过滤器 xwork-core-2.3.1.1.jar # 验证工具 freemarker-2.3.18.jar # 标签 javassist-3.11.0.GA.jar # 动态代理 commons-fileupload-1.2.2.jar commons-io-2.0.1.jar # 文件处理 commons-lang-2.5.jar # 基础包 ognl-3.0.3.jar # 表达式语言 2.web.xml文件中配置过滤器 &amp;lt;filter&amp;gt; &amp;lt;filter-name&amp;gt;struts&amp;lt;/filter-name&amp;gt; &amp;lt;filter-class&amp;gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&amp;lt;/filter-class&amp;gt; &amp;lt;/filter&amp;gt; &amp;lt;filter-mapping&amp;gt; &amp;lt;filter-name&amp;gt;struts&amp;lt;/filter-name&amp;gt; &amp;lt;url-pattern&amp;gt;/*&amp;lt;/url-pattern&amp;gt; &amp;lt;/filter-mapping&amp;gt; 3.写jsp页面，get或post路径为struts2的名称空间、扩展名，被配置的struts2过滤器处理 3.写Action类（继承ActionSupport类） 4.配置src/struts.xml文件与src/struts.properties文件，映射类、方法等到请求路径，映射返回字符串到任何方式  核心包：8个 struts2-core-2.</description>
    </item>
    
    <item>
      <title>Spring</title>
      <link>https://example.com/docs/backend/spring/</link>
      <pubDate>Thu, 11 Oct 2018 14:38:14 +0800</pubDate>
      
      <guid>https://example.com/docs/backend/spring/</guid>
      <description>下载  spring现在maven或gradle发布 官方引用方式 http://projects.spring.io/spring-framework/ maven发布地址 http://maven.springframework.org/release/org/springframework/spring/  特点 spring 是轻量级的，模块形式，无侵入或少侵入设计的（6个模块） dao orm aop jee web core ioc 动态代理 机制 bean或注解声明的没有接口的类：CGlib生成动态代理 有接口的类:Proxy生成代理，但是生成的类是接口类型 # cglib项目并入到spring项目中来了 ##　Proxy生成动态代理要求被代理的类必须有接口 结论 进行了事务包装（动态代理过的）有接口的类，注入（service实例）时，只能用接口接收 spring 3.2新特性 基于注解的注入测试类@RunW.. 为什么spring? 解耦 用spring 容器提供服务 单例 aop服务（权限拦截等） 辅助类等  功能  1.javaBean 的创建、关系与设置 2.声明式事务处理 3.定时器，远程调用  术语  pojo: pure old java object ,不实现任何接口 ioc inversion of control 控制反转（spring创建一个类的实例 ，注入到当前类中） di dependence injection 依赖注入  整合 spring boot spring integration  spring boot 用于在maven中快速构建spring项目  使用 1.</description>
    </item>
    
    <item>
      <title>Hibernate</title>
      <link>https://example.com/docs/backend/hibernate/</link>
      <pubDate>Thu, 11 Oct 2018 11:47:56 +0800</pubDate>
      
      <guid>https://example.com/docs/backend/hibernate/</guid>
      <description>基本概念：  o-&amp;gt; hibernate 相当于dao层，层次划分中是访问层，解决增、删、改、查、批处理五个问题 o-&amp;gt; hibernate实现orm(对象关系映射标准，完全面向对象编程思想) DBUtils与i/mybatis 与hibernate 是同样的，同样实现的是orm标准 它们的区别在于 hibernate中不写sql语句 ibatis中写少量sql语句 DBUtils中写sql语句 它们的另一个相同点是 底层全都是jdbc o-&amp;gt; 结构对应 javabean中的 类，对象，属性 数据库中的 表，记录，字段 o-&amp;gt; hql hibernate query language，hibernate自己的sql语言，需要使用antlr jar包中的方法内部转换成sql语言才能使用 o-&amp;gt; 正向工程：JavaBean生成表，反向工程：表生成JavaBean  优点  1.完全面向对象编程思想，无sql 2.减少代码 3.控制数据库访问，降低访问数据库的频率（第一次访问后，数据存储在内存的缓存中），提升效率 4.hibernate具有独立性（访问层随时可以更换）  特性  不写hbm.xml映射文件，而是基于注解的验证 hibernate3.6之后可以基于注解对javaBean的数据进行验证（jsr303标准）  目录  . # hibernate程序包 documentation # 文档 lib # 所有依赖包 project # 源码文件  加载顺序  后面的覆盖前面的 hibernate.properties中的配置被覆盖 # 因为该文件中的配置在new Configuration() 的时候就加载，而之后的xml配置文件是调用configuration.addResource()的方法加载的，新加载的配置覆盖了原来的配置  使用 1.导入核心包(10 + 1个) hibernate3.</description>
    </item>
    
    <item>
      <title>Nodejs</title>
      <link>https://example.com/docs/backend/nodejs/</link>
      <pubDate>Thu, 11 Oct 2018 10:33:48 +0800</pubDate>
      
      <guid>https://example.com/docs/backend/nodejs/</guid>
      <description>特点 commonJs规范 # 用于构建模块 javascript书写(v8引擎) # 关键字1 # 原因1: 成熟的事件驱动模式 ## 原因2: 没有i/o库, 没有历史包袱 ## 原因3: v8性能好 # js设计之初就可以运行在后端 单线程 # 关键字2 非阻塞io(non-blocking i/o model) # 关键字3 ## io与数据处理分离（所以必须异步） ## 线程池结合event-driven实现 事件驱动(event-driven) # 关键字4 ## event loop[while(true)] -&amp;gt; watcher -&amp;gt; handles ### event loop每一周询问多个watcher是否有事件 ### http模块就是启动了一个watcher,所以执行后进程不结束 # 注: event loop中没有watcher时进程退出 ### 其它watcher有 timer, fs, udp/req, process ### watcher产生事件后, event loop取到并执行其handle(回调函数) ## 不同操作系统中event driven的实现: ### windows: IOCP, Linux: epoll, Mac:kqueue 异步操作 # 书写难度的解决 ## go语言有协程(coroutine)而node.</description>
    </item>
    
    <item>
      <title>Hadoop</title>
      <link>https://example.com/docs/backend/hadoop/</link>
      <pubDate>Thu, 11 Oct 2018 10:05:41 +0800</pubDate>
      
      <guid>https://example.com/docs/backend/hadoop/</guid>
      <description>发展 google gfs mapReduce # 并行计算框架 big-table hadoop1.0 hdfs mapReduce hadoop2.0 hdfs # Hadoop Distributed File System　yarn # Yet Another Resource Negotiator资源管理调度系统 # 在hdfs上运行计算框架(如mapReduce, storm, spark)  原理 hdfs 模块 client nameNode # 用于注册文件 ## 2.0后可以有多个nameNode metadata # 数据的描述信息 dataNode # 数据在dataNode间水平传递 关系 client rpc nameNode 结构 metadata /test/a.log, 3, {blk_1,blk_2}, [{blk_1:[h0,h1,h3]},{blk_2:[h0,h2,h4]}] mapReduce Map: 切分，并行计算 Reduce: 从map中取多个计算结果，进行合并  组件 ambari # 安装、部署、配置和管理 hdfs # 分布式文件系统 hive # 数据仓库 pig # 数据流处理 mahout # 数据挖掘 mapreduce flume # 日志收集 hbase # 实时分布式, bigtable数据库 sqoop # etl zookeeper  框架 CDH cloudera HDP hortonworks data platform 应用框架 sqoop 在hdfs(hive)与关系型数据库之间数据相互转移 phoenix 介绍 打造更快的sql查询，面向hbase与hdfs之上的其它nosql数据库 特征 通过jdbc进行交互 shark 介绍 hive on spark 特点 并行job处理比mapReduce快100倍 ganglia 分布式监控系统，用于监视和显示集群中节点的各种状态信息，如cpu, mem, 硬盘利用率, i/o负载, 网络流量等，历史数据生成曲线图，通过php页面显现。 存储框架 hive 功能 将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为mapReduce运行。 缺点 底层使用mapReduce引擎，是一个批处理过程，难以满足查询的交互性 hbase 特征 分布式的，面向列的开源nosql数据库，列可以动态增加 基于hadoop的bigTable 不同于一般关系数据库，是一个适合于非结构化数据存储的数据库 自动切分数据 并发读写 缺点 只能按照row key来查询 master宕机，整个系统挂掉 计算框架 mr 离线计算框架 spark 介绍 内存计算框架 apache托管UC Berkeley AMP lab开源的类hadoop 通用并行框架 mapreduce中间输出结果可以保存在内存中，不再需要读写hdfs 是scala语言实现的 特点 准实时，收集成rdd后处理 不支持事务 技术 spark rdd spark streaming spark sql drill google dremel 的开源版本 storm 介绍 实时视图计算框架 纯实时 支持事务 特点 结合kafka impala 介绍 实时视图计算框架 纯实时 支持事务 特点 结合kafka  部署 本地模式 伪分布模式(学习用) 集群模式 例子 软件结构 0 jdk, hadoop NameNode, DFSZKFailoverController 1 jdk, hadoop NameNode, DFSZKFailoverController 2 jdk, hadoop ResourceManager 3 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain 4 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain 5 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain zookeeper 配置conf/zoo.</description>
    </item>
    
    <item>
      <title>服务器</title>
      <link>https://example.com/docs/backend/server/</link>
      <pubDate>Wed, 10 Oct 2018 17:16:29 +0800</pubDate>
      
      <guid>https://example.com/docs/backend/server/</guid>
      <description>nginx 结构 一个主进程(root权限运行)和多个工作进程(普通权限运行)  模块 handler filter upstream load-balance  功能  http 可以保持session， 相同的ip分配到同一个服务器上 缓存静态页面到内存，建立索引与自动索引 反向代理 负载均衡 模块化 过滤器 gzipping, byte ranges, chunked responses, SSI-filter 支持SSL与TLS SNI imap/pop3代理  命令 nginx -c /etc/nginx/nginx.conf nginx -s quit nginx -s stop nginx -s reload # 重载设置 ## service nginx reload nginx -v # 查看版本 ## -V nginx -t [-c nginx.conf] # 检查配置文件是否正确 nginx -h # 查看帮助 ## -? pkill -9 nginx kill -HUP `nginx.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/docs/backend/elasticsearch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/docs/backend/elasticsearch/</guid>
      <description>介绍 分布式实时lucene  使用 ./bin/elasticsearch curl http://localhost:9200  命令 elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name  概念存储 index type # document中加_type field实现 # 所以不同type中的field在index要唯一，否则冲突 # 对field排序会载入所有type的document document # 对应lucene中的key value倒排文档 # 对就一个请求的json对象 field mapping # 定义type的field，映射json到document field  设置 config/elasticsearch.yml action.auto_create_index: -l*, +z* # 自动创建，以z开头和非l开头的索引 action.destructive_requires_name: true # 允许通配删index http.cors.enables: true http.cors.allow-origin: &amp;quot;*&amp;quot; cluster.name: c1 node.name: n1 node.master: true node.data: true transport.host: localhost transport.tcp.port: 9300 network.host: 0.0.0.0 # 修改es监听地址，别的机器也可以访问。同时设置bind_host和publish_host # 需要设置transport.host:localhost network.bind_host # 节点绑定ip network.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/docs/backend/lucene/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/docs/backend/lucene/</guid>
      <description>原理 block k-d tree 倒排索引 词典 排序数组 # 为了二分查找 # 实现简单，性能差 哈希表 # 性能好，占内存大 跳跃表 # 内存小且可调节, 模糊查询不好 B/B+树 # 磁盘索引 ，更新方便，检索慢 trie树 # 效率与字符串长度有关，只适合做英文词典 dat # 可做中文词典，内存占用小 fst # 共享前缀，内存占用小，要求输入有序，不易更新 内存存前缀索引、磁盘存后缀词块 倒排表 正向文件 # 行式存储，原始文档 doc-values # 列式存储，文档号到值的映射 文件指纹  概念 index # 一个倒排表，对应一个目录 segment # index的存储单元，包含多个文档 document # 创建单位 field # 文档里的键值对 term # 分词后的字符串 analyzer tokenizer # 切分文本到索引单元 tokenfilter # 对token预处理  常识 特性 索引 高亮 命中率排序 分词 与数据库的区别：数据库注重存储、全文检索注重查询 其它搜索：多媒体搜索 索引库(文件夹 或 内存中)： 只存储了商品的基本信息 索引库与数据库定时同步 索引库 -&amp;gt; document -&amp;gt; field # field是键值对,值只能存数据 同步 IndexWriter:addDocumnet(),delteDocument(),updateDocument() 查询 IndexSearch:search(),get() Field的内部结构 # 不存不索引会报错 Store:控制此Field字段是否存储到索引库中 Index:是否建立索引（索引不区分大小写,过滤词不创建索引） NO:不建立索引，可以通过field的key查到，但是不能通过关键字查询到 NOT_ANALYZED:建立索引，但是不分词 ANALYZEd:建立索引又分词  使用到的对象 Directory Analyzer TokenStream tokenStream = analyzer.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/docs/backend/shiro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/docs/backend/shiro/</guid>
      <description>shiro 功能 Authenticator # SecurityManager继承Authenticator public AuthenticationInfo authenticate(AuthenticationToken authenticationToken) throws AuthenticationException; permission 概念 subject resource permission role 隐式角色 显示角色 配置 shiro.ini [users] zhang=123, role1, role2 # 用户名=密码, 角色1, 角色2 判断角色 o-&amp;gt; subject.hasRole(&amp;quot;admin&amp;quot;); o-&amp;gt; @RequiresRoles(&amp;quot;admin&amp;quot;) @RequiresRoles(value={“admin”, “user”}, logical= Logical.AND) # 表示当前Subject需要角色admin和user。 o-&amp;gt; &amp;lt;shiro:hasRole name=&amp;quot;admin&amp;quot;&amp;gt;&amp;lt;/shiro:hasRole&amp;gt; 权限注解 @RequiresAuthentication # 表示当前Subject已经通过login进行了身份验证；即Subject. isAuthenticated()返回true。 @RequiresUser # 表示当前Subject已经身份验证或者通过记住我登录的。 @RequiresGuest # 表示当前Subject没有身份验证或通过记住我登录过，即是游客身份。 @RequiresPermissions (value={“user:a”, “user:b”}, logical= Logical.OR) # 表示当前Subject需要权限user:a或user:b。 credential 散列 String str = &amp;quot;hello&amp;quot;; String salt = &amp;quot;123&amp;quot;; //内部使用MessageDigest String simpleHash 密码生成工具 //输入明文密码得到密文密码 String encryptPassword(Object plaintextPassword) throws IllegalArgumentException; //匹配用户输入的token的凭证（未加密）与系统提供的凭证（已加密） boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info); filter NameableFilter ＃根据名字找到相应的拦截器实例 OncePerRequestFilter # 控制开启、关闭拦截器实例 ShiroFilter # 安全控制 AdviceFilter # aop preHandle # 前置增强 postHandle # 后置增强 afterCompletion # 后置最终增强(异常也执行，相当于finally的概念) PathMatchingFilter # 匹配请求路径 AccessControlFilter # 允许或拒绝访问，拒绝时如何处理 jsp标签 &amp;lt;%@taglib prefix=&amp;quot;shiro&amp;quot; uri=&amp;quot;http://shiro.</description>
    </item>
    
  </channel>
</rss>