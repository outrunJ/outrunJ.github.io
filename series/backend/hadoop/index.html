<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>Hadoop - outrunJ笔记</title>
  <meta property="og:title" content="Hadoop - outrunJ笔记" />
  <meta name="twitter:title" content="Hadoop - outrunJ笔记" />
  <meta name="description" content="发展 google gfs mapReduce # 并行计算框架 big-table hadoop1.0 hdfs mapReduce hadoop2.0 hdfs # Hadoop Distributed File System　yarn # Yet Another Resource Negotiator资源管理调度系统 # 在hdfs上运行计算框架(如mapReduce, storm, spark)  原理 hdfs 模块 client nameNode # 用于注册文件 ## 2.0后可以有多个nameNode metadata # 数据的描述信息 dataNode # 数据在dataNode间水平传递 关系 client rpc nameNode 结构 metadata /test/a.log, 3, {blk_1,blk_2}, [{blk_1:[h0,h1,h3]},{blk_2:[h0,h2,h4]}] mapReduce Map: 切分，并行计算 Reduce: 从map中取多个计算结果，进行合并  组件 ambari # 安装、部署、配置和管理 hdfs # 分布式文件系统 hive # 数据仓库 pig # 数据流处理 mahout # 数据挖掘 mapreduce flume # 日志收集 hbase # 实时分布式, bigtable数据库 sqoop # etl zookeeper  框架 CDH cloudera HDP hortonworks data platform 应用框架 sqoop 在hdfs(hive)与关系型数据库之间数据相互转移 phoenix 介绍 打造更快的sql查询，面向hbase与hdfs之上的其它nosql数据库 特征 通过jdbc进行交互 shark 介绍 hive on spark 特点 并行job处理比mapReduce快100倍 ganglia 分布式监控系统，用于监视和显示集群中节点的各种状态信息，如cpu, mem, 硬盘利用率, i/o负载, 网络流量等，历史数据生成曲线图，通过php页面显现。 存储框架 hive 功能 将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为mapReduce运行。 缺点 底层使用mapReduce引擎，是一个批处理过程，难以满足查询的交互性 hbase 特征 分布式的，面向列的开源nosql数据库，列可以动态增加 基于hadoop的bigTable 不同于一般关系数据库，是一个适合于非结构化数据存储的数据库 自动切分数据 并发读写 缺点 只能按照row key来查询 master宕机，整个系统挂掉 计算框架 mr 离线计算框架 spark 介绍 内存计算框架 apache托管UC Berkeley AMP lab开源的类hadoop 通用并行框架 mapreduce中间输出结果可以保存在内存中，不再需要读写hdfs 是scala语言实现的 特点 准实时，收集成rdd后处理 不支持事务 技术 spark rdd spark streaming spark sql drill google dremel 的开源版本 storm 介绍 实时视图计算框架 纯实时 支持事务 特点 结合kafka impala 介绍 实时视图计算框架 纯实时 支持事务 特点 结合kafka  部署 本地模式 伪分布模式(学习用) 集群模式 例子 软件结构 0 jdk, hadoop NameNode, DFSZKFailoverController 1 jdk, hadoop NameNode, DFSZKFailoverController 2 jdk, hadoop ResourceManager 3 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain 4 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain 5 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain zookeeper 配置conf/zoo.">
  <meta property="og:description" content="发展 google gfs mapReduce # 并行计算框架 big-table hadoop1.0 hdfs mapReduce hadoop2.0 hdfs # Hadoop Distributed File System　yarn # Yet Another Resource Negotiator资源管理调度系统 # 在hdfs上运行计算框架(如mapReduce, storm, spark)  原理 hdfs 模块 client nameNode # 用于注册文件 ## 2.0后可以有多个nameNode metadata # 数据的描述信息 dataNode # 数据在dataNode间水平传递 关系 client rpc nameNode 结构 metadata /test/a.log, 3, {blk_1,blk_2}, [{blk_1:[h0,h1,h3]},{blk_2:[h0,h2,h4]}] mapReduce Map: 切分，并行计算 Reduce: 从map中取多个计算结果，进行合并  组件 ambari # 安装、部署、配置和管理 hdfs # 分布式文件系统 hive # 数据仓库 pig # 数据流处理 mahout # 数据挖掘 mapreduce flume # 日志收集 hbase # 实时分布式, bigtable数据库 sqoop # etl zookeeper  框架 CDH cloudera HDP hortonworks data platform 应用框架 sqoop 在hdfs(hive)与关系型数据库之间数据相互转移 phoenix 介绍 打造更快的sql查询，面向hbase与hdfs之上的其它nosql数据库 特征 通过jdbc进行交互 shark 介绍 hive on spark 特点 并行job处理比mapReduce快100倍 ganglia 分布式监控系统，用于监视和显示集群中节点的各种状态信息，如cpu, mem, 硬盘利用率, i/o负载, 网络流量等，历史数据生成曲线图，通过php页面显现。 存储框架 hive 功能 将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为mapReduce运行。 缺点 底层使用mapReduce引擎，是一个批处理过程，难以满足查询的交互性 hbase 特征 分布式的，面向列的开源nosql数据库，列可以动态增加 基于hadoop的bigTable 不同于一般关系数据库，是一个适合于非结构化数据存储的数据库 自动切分数据 并发读写 缺点 只能按照row key来查询 master宕机，整个系统挂掉 计算框架 mr 离线计算框架 spark 介绍 内存计算框架 apache托管UC Berkeley AMP lab开源的类hadoop 通用并行框架 mapreduce中间输出结果可以保存在内存中，不再需要读写hdfs 是scala语言实现的 特点 准实时，收集成rdd后处理 不支持事务 技术 spark rdd spark streaming spark sql drill google dremel 的开源版本 storm 介绍 实时视图计算框架 纯实时 支持事务 特点 结合kafka impala 介绍 实时视图计算框架 纯实时 支持事务 特点 结合kafka  部署 本地模式 伪分布模式(学习用) 集群模式 例子 软件结构 0 jdk, hadoop NameNode, DFSZKFailoverController 1 jdk, hadoop NameNode, DFSZKFailoverController 2 jdk, hadoop ResourceManager 3 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain 4 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain 5 jdk, hadoop, zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain zookeeper 配置conf/zoo.">
  <meta name="twitter:description" content="发展 google gfs mapReduce # 并行计算框架 big-table hadoop1.0 hdfs mapReduce hadoop2.0 hdfs # Hadoop Distributed File System　yarn # Yet Another Resource Negotiator资源管理调度系统 # 在hdfs上运行计算框架(如mapReduce, storm, …">
  <meta name="author" content="outrunJ"/>
  <meta property="og:site_name" content="outrunJ笔记" />
  <meta property="og:url" content="http://shenwenqing.com/series/backend/hadoop/" />
  <meta property="og:type" content="article" />
  <meta name="twitter:card" content="summary" />
  <meta name="generator" content="Hugo 0.49-DEV" />
  <link rel="stylesheet" href="/css/style.css" media="all" />
  <link rel="stylesheet" href="/css/syntax.css" media="all" />
  <link rel="stylesheet" href="/css/custom.css" media="all" />
  <script src="/js/jquery-3.3.1.min.js"></script>
  <script defer src="/js/fontawesome.js"></script>
</head>

<body>

<header class="site-header">
  <nav class="site-navi">
    <h1 class="site-title"><a href="/">outrunJ笔记</a></h1>
    <ul class="site-navi-items">
      <li class="site-navi-item-categories"><a href="/categories/" title="Categories">Categories</a></li>
      <li class="site-navi-item-tags"><a href="/tags/" title="Tags">Tags</a></li>
      <li class="site-navi-item-archives"><a href="/archives/" title="Archives">Archives</a></li>
      <li class="site-navi-item-about"><a href="/about/" title="About">About</a></li>
    </ul>
  </nav>
</header>
<hr class="site-header-bottom">

  <div class="main" role="main">
    <article class="article">
      
      
      <h1 class="article-title">Hadoop</h1>
      
      <hr class="article-title-bottom">
      <ul class="article-meta">
        <li class="article-meta-date"><time>October 11, 2018</time></li>
      </ul>
      
      

<h1 id="发展">发展</h1>

<pre><code>google
        gfs
        mapReduce
                # 并行计算框架
        big-table
hadoop1.0 
hdfs
        mapReduce
hadoop2.0
        hdfs
                # Hadoop Distributed File System　
        yarn
                # Yet Another Resource Negotiator资源管理调度系统
                # 在hdfs上运行计算框架(如mapReduce, storm, spark)
</code></pre>

<h1 id="原理">原理</h1>

<pre><code>hdfs
    模块
            client
            nameNode                                                # 用于注册文件
                                                                    ## 2.0后可以有多个nameNode
                    metadata                                        # 数据的描述信息
            dataNode                                                # 数据在dataNode间水平传递
    关系
            client rpc nameNode
    结构
            metadata
                    /test/a.log, 3, {blk_1,blk_2}, [{blk_1:[h0,h1,h3]},{blk_2:[h0,h2,h4]}]
mapReduce
    Map: 切分，并行计算
    Reduce: 从map中取多个计算结果，进行合并
</code></pre>

<h1 id="组件">组件</h1>

<pre><code>ambari
        # 安装、部署、配置和管理
hdfs
        # 分布式文件系统
hive
        # 数据仓库
pig
        # 数据流处理
mahout
        # 数据挖掘
mapreduce
flume
        # 日志收集
hbase
        # 实时分布式, bigtable数据库
sqoop
        # etl
zookeeper
</code></pre>

<h1 id="框架">框架</h1>

<pre><code>CDH
    cloudera
HDP
    hortonworks data platform
应用框架
    sqoop
        在hdfs(hive)与关系型数据库之间数据相互转移
    phoenix
        介绍
                打造更快的sql查询，面向hbase与hdfs之上的其它nosql数据库
        特征
                通过jdbc进行交互
    shark
        介绍
                hive on spark
        特点
                并行job处理比mapReduce快100倍
    ganglia
        分布式监控系统，用于监视和显示集群中节点的各种状态信息，如cpu, mem, 硬盘利用率, i/o负载, 网络流量等，历史数据生成曲线图，通过php页面显现。
存储框架
    hive
        功能
                将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为mapReduce运行。
        缺点
                底层使用mapReduce引擎，是一个批处理过程，难以满足查询的交互性
    hbase
        特征
                分布式的，面向列的开源nosql数据库，列可以动态增加
                基于hadoop的bigTable
                不同于一般关系数据库，是一个适合于非结构化数据存储的数据库
                自动切分数据
                并发读写
        缺点
                只能按照row key来查询
                master宕机，整个系统挂掉
计算框架
    mr  
        离线计算框架
    spark
        介绍
                内存计算框架
                apache托管UC Berkeley AMP lab开源的类hadoop 通用并行框架
                mapreduce中间输出结果可以保存在内存中，不再需要读写hdfs
                是scala语言实现的
        特点
                准实时，收集成rdd后处理
                不支持事务 
        技术 
                spark rdd
                spark streaming
                spark sql
    drill
        google dremel 的开源版本
    storm
        介绍        
                实时视图计算框架
                纯实时
                支持事务
        特点
                结合kafka 
    impala
        介绍        
                实时视图计算框架
                纯实时
                支持事务
        特点
                结合kafka 
</code></pre>

<h1 id="部署">部署</h1>

<pre><code>本地模式
伪分布模式(学习用)
集群模式
例子
    软件结构
            0        jdk, hadoop                        NameNode, DFSZKFailoverController
            1        jdk, hadoop                        NameNode, DFSZKFailoverController
            2        jdk, hadoop                        ResourceManager
            3        jdk, hadoop, zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
            4        jdk, hadoop, zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
            5        jdk, hadoop, zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
    zookeeper
        配置conf/zoo.cfg
                tickTime=2000                        # 心跳间隔(ms)
                initLimit=10                        # 初始化时最多容忍心跳次数
                syncLimit=5                        # 同步失败最多容忍心跳次数
                dataDir=/usr/local/zookeeper/data        # 运行时文件目录
                clientPort=2181                # 运行端口号
                server.1=主机名或ip:2888:3888        # 服务运行端口与选举端口
                server.2=主机名或ip:2888:3888
                server.3=主机名或ip:2888:3888
        命令
                ./bin/zkServer.sh start
                ./bin/zkServer.sh status
                jps                                        # 显示名为QuorumPeerMain
    hadoop
        hadoop-env.sh
            export JAVA_HOME=
        core-site.xml
            &lt;configuration&gt;
                &lt;property&gt;
                        &lt;name&gt;fs.defaultFS&lt;/name&gt;
                        &lt;value&gt;hdfs://ns1&lt;/value&gt;
                &lt;/property&gt;
                &lt;property&gt;
                        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
                        &lt;value&gt;/usr/local/hadoop-2.2.0/tmp&lt;/value&gt;
                &lt;/property&gt;
                &lt;property&gt;
                        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
                        &lt;value&gt;192.168.56.13:2181, 192.168.56.14:2181, 192.168.56.15:2181&lt;/value&gt;
                &lt;/property&gt;
            &lt;/configuration&gt;
        hdfs-site.xml
            &lt;property&gt;
                &lt;name&gt;dfs.nameservices&lt;/name&gt;
                &lt;value&gt;ns1&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;
                &lt;value&gt;nn1,nn2&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;
                &lt;value&gt;192.168.56.10:9000&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;
                &lt;value&gt;192.168.56.10:50070&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;
                &lt;value&gt;192.168.56.11:9000&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;
                &lt;value&gt;192.168.56.11:50070&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
                &lt;value&gt;qjournal://192.168.56.13:8485;192.168.56.14:8485;192.168.56.15:8485&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
                &lt;value&gt;/usr/local/hadoop-2.2.0/journal&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
                &lt;value&gt;true&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;
                &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
                &lt;value&gt;sshfence&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
                &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
            &lt;/property&gt;
        mapred-site.xml
            &lt;property&gt;
                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
                &lt;value&gt;yarn&lt;/value&gt;
            &lt;/property&gt;
        yarn-site.xml
            &lt;property&gt;
                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
                &lt;value&gt;192.168.56.12&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
            &lt;/property&gt;
        etc/hadoop/slaves
            192.168.56.13
            192.168.56.14
            192.168.56.15
    收尾
        o-&gt; ssh免登录(0到1,2,3,4,5)
                ssh-keygen -t rsa
                ssh-copy-id -i 192.168.56.11                # 这样就可以免登录访问192.168.56.11了
                                                        ## ssh-copy-id -i localhost 免登录自己

        o-&gt; 复制hadoop2.2.0(从0到1,2,3,4,5)

        o-&gt; 添加hadoop_home到环境变量
                etc/profile
                        export HADOOP_HOME=/usr/local/hadoop-2.2.0
                        export PATH=$PATH:$HADOOP_HOME/bin
    启动
        0 上启动
                ./sbin/hadoop-daemons.sh start journalnode
        0 上格式化namenode
                hadoop namenode -format
</code></pre>

<h1 id="相关">相关</h1>

<pre><code>bigTable
gfs
dremel
    介绍
            google的交互式数据分析系统，构建于gfs上
    特点
            嵌套型数据的列存储
            多层查询
            减少查询的处理数据量，提升查询效率
</code></pre>

    </article>

    
<ul class="article-share">
  <li>
    <a href="https://twitter.com/share" class="twitter-share-button">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </li>
  <li>
    <div class="fb-share-button" data-href="http://shenwenqing.com/series/backend/hadoop/" data-layout="button_count" data-action="like" data-size="small" data-show-faces="true" data-share="true"></div>
    <div id="fb-root"></div>
    <script>(function(d, s, id) {
      var js, fjs = d.getElementsByTagName(s)[0];
      if (d.getElementById(id)) return;
      js = d.createElement(s); js.id = id;
      js.src = "//connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v2.10";
      fjs.parentNode.insertBefore(js, fjs);
    }(document, 'script', 'facebook-jssdk'));</script>
  </li>
  <li>
    <script src="https://apis.google.com/js/platform.js" async defer></script>
    <g:plus action="share"></g:plus>
  </li>
  <li>
    <a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="basic-label-counter" data-hatena-bookmark-lang="en" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
  </li>
  <li>
    <a data-pocket-label="pocket" data-pocket-count="horizontal" class="pocket-btn" data-lang="en"></a>
    <script>!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script>
  </li>
</ul>


    <ul class="pager article-pager">
      <li class="pager-newer">
          <a href="/series/backend/nodejs/" data-toggle="tooltip" data-placement="top" title="Nodejs">&lt; Newer</a>
      </li>
      <li class="pager-older">
        <a href="/series/backend/elasticsearch/" data-toggle="tooltip" data-placement="top" title="Elasticsearch">Older &gt;</a>
      </li>
    </ul>
  </div>


<div class="site-footer">
  <div class="copyright">&copy; Copyright 2017 outrunJ</div>
  <ul class="site-footer-items">
    <li class="site-footer-item-about"><a href="/about/" title="About">About</a></li>
  </ul>
  <div class="powerdby">
    Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://github.com/taikii/whiteplain">Whiteplain</a>
  </div>
</div>
<script src="/js/script.js"></script>
<script src="/js/custom.js"></script>


</body>
</html>
