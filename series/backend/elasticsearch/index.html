<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>Elasticsearch - outrunJ笔记</title>
  <meta property="og:title" content="Elasticsearch - outrunJ笔记" />
  <meta name="twitter:title" content="Elasticsearch - outrunJ笔记" />
  <meta name="description" content="介绍  分布式实时lucene  使用  ./bin/elasticsearch curl http://localhost:9200  命令  elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name  概念存储  index type # document中加_type field实现 # 所以不同type中的field在index要唯一，否则冲突 # 对field排序会载入所有type的document document # 对应lucene中的key value倒排文档 # 对就一个请求的json对象 field mapping # 定义type的field，映射json到document field  设置 config/elasticsearch.yml action.auto_create_index: -l*, &#43;z* # 自动创建，以z开头和非l开头的索引 action.destructive_requires_name: true # 允许通配删index http.cors.enables: true http.cors.allow-origin: &quot;*&quot; cluster.name: c1 node.name: n1 node.master: true node.data: true transport.host: localhost transport.tcp.port: 9300 network.host: 0.0.0.0 # 修改es监听地址，别的机器也可以访问。同时设置bind_host和publish_host # 需要设置transport.">
  <meta property="og:description" content="介绍  分布式实时lucene  使用  ./bin/elasticsearch curl http://localhost:9200  命令  elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name  概念存储  index type # document中加_type field实现 # 所以不同type中的field在index要唯一，否则冲突 # 对field排序会载入所有type的document document # 对应lucene中的key value倒排文档 # 对就一个请求的json对象 field mapping # 定义type的field，映射json到document field  设置 config/elasticsearch.yml action.auto_create_index: -l*, &#43;z* # 自动创建，以z开头和非l开头的索引 action.destructive_requires_name: true # 允许通配删index http.cors.enables: true http.cors.allow-origin: &quot;*&quot; cluster.name: c1 node.name: n1 node.master: true node.data: true transport.host: localhost transport.tcp.port: 9300 network.host: 0.0.0.0 # 修改es监听地址，别的机器也可以访问。同时设置bind_host和publish_host # 需要设置transport.">
  <meta name="twitter:description" content="介绍  分布式实时lucene  使用  ./bin/elasticsearch curl http://localhost:9200  命令  elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name  概念存储  index type # document中加_type field实现 # 所以不同type中 …">
  <meta name="author" content="outrunJ"/>
  <meta property="og:site_name" content="outrunJ笔记" />
  <meta property="og:url" content="http://shenwenqing.com/series/backend/elasticsearch/" />
  <meta property="og:type" content="article" />
  <meta name="twitter:card" content="summary" />
  <meta name="generator" content="Hugo 0.49-DEV" />
  <link rel="stylesheet" href="/css/style.css" media="all" />
  <link rel="stylesheet" href="/css/syntax.css" media="all" />
  <link rel="stylesheet" href="/css/custom.css" media="all" />
  <script src="/js/jquery-3.3.1.min.js"></script>
  <script defer src="/js/fontawesome.js"></script>
</head>

<body>

<header class="site-header">
  <nav class="site-navi">
    <h1 class="site-title"><a href="/">outrunJ笔记</a></h1>
    <ul class="site-navi-items">
      <li class="site-navi-item-categories"><a href="/categories/" title="Categories">Categories</a></li>
      <li class="site-navi-item-tags"><a href="/tags/" title="Tags">Tags</a></li>
      <li class="site-navi-item-archives"><a href="/archives/" title="Archives">Archives</a></li>
      <li class="site-navi-item-about"><a href="/about/" title="About">About</a></li>
    </ul>
  </nav>
</header>
<hr class="site-header-bottom">

  <div class="main" role="main">
    <article class="article">
      
      
      <h1 class="article-title">Elasticsearch</h1>
      
      <hr class="article-title-bottom">
      <ul class="article-meta">
        <li class="article-meta-date"><time>October 11, 2018</time></li>
      </ul>
      
<aside class="toc">
  <nav id="TableOfContents">
<ul>
<li><a href="#介绍">介绍</a></li>
<li><a href="#使用">使用</a></li>
<li><a href="#命令">命令</a></li>
<li><a href="#概念存储">概念存储</a></li>
<li><a href="#设置">设置</a></li>
<li><a href="#接口">接口</a>
<ul>
<li><a href="#数据对象">数据对象</a></li>
</ul></li>
<li><a href="#插件">插件</a>
<ul>
<li><a href="#ik">ik</a></li>
<li><a href="#pinyin">pinyin</a></li>
</ul></li>
<li><a href="#工具">工具</a></li>
<li><a href="#client">client</a></li>
</ul>
</nav>
</aside>
      

<h1 id="介绍">介绍</h1>

<pre><code>    分布式实时lucene
</code></pre>

<h1 id="使用">使用</h1>

<pre><code>    ./bin/elasticsearch
    curl http://localhost:9200
</code></pre>

<h1 id="命令">命令</h1>

<pre><code>    elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name
</code></pre>

<h1 id="概念存储">概念存储</h1>

<pre><code>    index
            type
                    # document中加_type field实现
                    # 所以不同type中的field在index要唯一，否则冲突
                    # 对field排序会载入所有type的document
                    document
                            # 对应lucene中的key value倒排文档
                            # 对就一个请求的json对象
                            field
                                    mapping
                                            # 定义type的field，映射json到document field        
</code></pre>

<h1 id="设置">设置</h1>

<pre><code>config/elasticsearch.yml
        action.auto_create_index: -l*, +z*
                # 自动创建，以z开头和非l开头的索引
        action.destructive_requires_name: true
                # 允许通配删index
        http.cors.enables: true
        http.cors.allow-origin: &quot;*&quot;
        cluster.name: c1
        node.name: n1
        node.master: true
        node.data: true
        transport.host: localhost
        transport.tcp.port: 9300
        network.host: 0.0.0.0
                # 修改es监听地址，别的机器也可以访问。同时设置bind_host和publish_host
                # 需要设置transport.host:localhost
        network.bind_host
                # 节点绑定ip
        network.publish_host
                # 发布地址，其它节点通过这个地址通信 
        http.port: 9200
        transport.tcp.port
                # 通信端口，默认9300
        discovery.zen.minimum_master_nodes: 2

o-&gt; 可用配置
cluster.name: myES_Cluster
node.name: ESNODE_CYR
node.master: true
node.data: true
transport.host: localhost
transport.tcp.port: 9300
http.port: 9200
network.host: 0.0.0.0
discovery.zen.minimum_master_nodes: 2
</code></pre>

<h1 id="接口">接口</h1>

<pre><code>索引
        put /index1
                # 创建index
                # get查询，delete删除
                settings
                mappings
                aliases:
        put /index1/_mapping/type2
        put /index1/type2/_mapping
                # 创建type或给已有type加mappings
                # get得到mapping信息
                properties
        put /index1/_settings
        put /index1/type1/1
                # 插入doc
                # get得到doc
                name: &quot;name1&quot;
_cat
        get /_cat/health?v
                # 集群健康
        get /_cat/nodes?v
                # 集群节点
        get /_cat/indices?v
                # 所有索引
_aliases
        post /_aliases
                # 索引别名
                actions:
                        add:
                                alias: &quot;my_index&quot;
                                index: &quot;my_index_v1&quot;
                        remove
_template
        put /_template/tpl1
                template: &quot;te*&quot;
                        # 匹配所有re开头的index
                settings:
                mappings:
_search
        post /index1/type1/_search
                # from size实时分页
                # scroll快照分页
                ?from=0&amp;size=50
                ?scroll=1m&amp;size=50
                        # 过期时间1分钟，每次返回50条
                ?search_type=scan&amp;scroll=1m
                        # scroll-scan分页不排序，更快,
_analyze
        post /index1/_analyze
                text: &quot;刘德华&quot;
                analyzer: &quot;analyzer1&quot;
_close
        post /index1/_close
                # 关闭索引，此后可以改settings
_open
        post /index1/_open
_cache
        post /index1/type1/_cache/clear?filter_keys=k1
                # 清空query filter的缓存
</code></pre>

<h2 id="数据对象">数据对象</h2>

<pre><code>_search
        query
                match
                        # 理解如何分词的, 会对field分词再查询
                        field1: 
                                query: &quot;a b&quot;
                                operator: &quot;and&quot;
                                minimum_should_match: &quot;75%&quot;
                                        # 匹配的query分词的最低占比
                match_all
                        # 默认，会查出所有文档
                multi_match
                        query: &quot;a b&quot;
                        fields: [&quot;field1&quot;, &quot;field2&quot;]
                match_phrase
                        # 所有term命中，并且位置邻接
                        field1: &quot;a b&quot;
                term
                        # 确切查询
                        field1: &quot;value1&quot;
                terms
                        # 多条件and
                        field1: [1,2,3]
                range
                        field1:
                                gt: 20
                                gte: 
                                lt:
                                lte:
                exists:
                        field: &quot;field1&quot;
                missing:
                        field: &quot;field1&quot;
                regexp
                        postcode: &quot;W[0-9].+&quot;
                wildcard
                        postcode: &quot;W?F*HW&quot;
                prefix
                        # 以某些字符开头
                        field1: &quot;a&quot;
                bool
                        # 分值计算来自must和should语句, must_not不影响
                        must
                                match
                        must_not
                        should: []
                        minimum_should_match: 2
                filtered
                        query
                        filter:
                                # filter的field会缓存起来
                                ## geo, and, or, not, script, numeric_range的默认不缓存
                                term:
                                        field1: &quot;a&quot;
                                        _cache_key: &quot;k1&quot;
                                        _cache: false
                                range:
                                        field1:
                                                gte: 0
        aggs
                diy1:
                        avg:
                                field: &quot;field1&quot;
                diy2:
                        terms:
                                # 聚合查询中的所有term
                                field: &quot;field1&quot;
        post_filter:
                # 对搜索结果进行过滤
                term:
                        field1: &quot;a&quot;
        sort: []
                # 默认升序，_score默认降序
                field1
                        order: &quot;desc&quot;
                                # asc
                        mode: &quot;min&quot;
                                # 对数组元素排序时的取值, 还有max, sum, avg, median
                        missing: &quot;field1&quot;
                &quot;_score&quot;,
        highlight
                pre_tags: [&quot;&lt;tag1&gt;&quot;]
                post_tags: [&quot;&lt;/tag1&gt;&quot;]
                fields:
                        content: {}
        simple_query_string:
                query: &quot;&quot;
                analyzer:
                fields: [&quot;body^5&quot;, &quot;_all&quot;]
                default_operator: &quot;and&quot;
mappings:
        type1:
                dynamic: true
                        # 默认true,自动给未知field建索引
                        # false: 忽略未知field， strict: 未知field报错
                include_in_all: false
                        # 默认不include
                _all:
                        # meta field
                        enabled: false
                                # 关闭all作用域
                        analyzer:
                                # 其实是search_analyzer
                        term_vector: no
                                # 对field建立词频向量空间
                        store: &quot;false&quot;
                _source:
                        #  是否保存内容
                        enabled: true
                properties:
                        field1:
                                type: “text”
                                        # text分词，keyword不分词，numeric, date, string
                                        # multi_field可定义多个field
                                fields:[]
                                        field1:
                                                type
                                store: &quot;yes&quot;
                                index: &quot;not_analyzed&quot;
                                        # analyzed
                                analyzer: &quot;ik_max_word&quot;
                                search_analyzer: &quot;ik_max_word&quot;
                                        # 默认为analyzer
                                include_in_all: &quot;true&quot;
                                        # 是否加入_all作用域
                                boost: 8
aliases:
        alias1:
                filter:
                        term: user: &quot;kimchy&quot;
                routing: &quot;kimchy&quot;
settings:
        # 有些设置不能动态修改
        index:
                number_of_shards: 3
                number_of_replicas: 2
                max_result_window: 10000
                        # from + size的上限，默认10000
                analysis:
                        tokenizer:
                                # 处理原始输入
                                tokenizer1
                                        type: &quot;pinyin&quot;
                                        pinyin_field1:

                        filter:
                                # tokenizer作为输入
                                filter1:
                                        type: &quot;pinyin&quot;
                                        pinyin_field1:
                        analyzer:
                                # 组合tokenizer和filter
                                analyzer1:
                                        type: &quot;custom&quot;
                                        tokenizer: &quot;ik_smart&quot;
                                        filter: [&quot;filter1&quot;, &quot;word_delimiter&quot;]
</code></pre>

<h1 id="插件">插件</h1>

<pre><code>使用
    复制到/plugins
    场景中，指定type:&quot;xx&quot;使用
</code></pre>

<h2 id="ik">ik</h2>

<pre><code>介绍
        elasticsearch-analysis-ik
安装
        mvn package
        unzip -d /elasticsearch/plugins/ik ./target/releases/elasticsearch-analysis-ik-1.8.0.zip
        重启elasticsearch
分词器
        ik_max_word
                curl -XGET 'http://localhost:9200/_analyze?pretty&amp;analyzer=ik_max_word' -d '联想是全球最大的笔记本厂商'
        ik_smart
                curl -XGET 'http://localhost:9200/_analyze?pretty&amp;analyzer=ik_smart' -d '联想是全球最大的笔记本厂商'
mapping type
        {
        &quot;properties&quot;: {
            &quot;content&quot;: {
            &quot;type&quot;: &quot;text&quot;,
            &quot;store&quot;: &quot;no&quot;,
            &quot;term_vector&quot;: &quot;with_positions_offsets&quot;,
            &quot;analyzer&quot;: &quot;ik_smart&quot;,
            &quot;search_analyzer&quot;: &quot;ik_smart&quot;,
            &quot;include_in_all&quot;: &quot;true&quot;,
            &quot;boost&quot;: 8
            }
        }
        }
</code></pre>

<h2 id="pinyin">pinyin</h2>

<pre><code>介绍
        elasticsearch-analysis-pinyin


o-&gt; 
&quot;analysis&quot; : {
        &quot;analyzer&quot; : {
                &quot;pinyin_analyzer&quot; : {
                        &quot;tokenizer&quot; : &quot;my_pinyin&quot;,
                    &quot;filter&quot; : &quot;word_delimiter&quot;
                }
        },
        &quot;tokenizer&quot; : {
                &quot;my_pinyin&quot; : {
                        # 单字
                        &quot;type&quot; : &quot;pinyin&quot;,
                    &quot;first_letter&quot; : &quot;none&quot;,
                    &quot;padding_char&quot; : &quot; &quot;
                },
                &quot;my_pinyin_fisrt_letter&quot; : {
                        # 首字母, 如北京为bj
                        &quot;type&quot; : &quot;pinyin&quot;,
                    &quot;first_letter&quot; : true,
                    &quot;padding_char&quot; : &quot; &quot;
                }, 
        }
}
o-&gt; pinyin
&quot;analysis&quot; : {
        &quot;tokenizer&quot; : {
                &quot;my_pinyin&quot; : {
                    &quot;type&quot; : &quot;pinyin&quot;,
                    &quot;keep_separate_first_letter&quot; : false,
                    &quot;keep_full_pinyin&quot; : true,
                    &quot;keep_original&quot; : true,
                    &quot;limit_first_letter_length&quot; : 16,
                    &quot;lowercase&quot; : true,
                    &quot;remove_duplicated_term&quot; : true
                }
        },
        &quot;analyzer&quot; : {
                &quot;pinyin_analyzer&quot; : {
                        &quot;tokenizer&quot; : &quot;my_pinyin&quot;
                }
        }
}
&quot;properties&quot;: {
        &quot;name&quot;: {
                &quot;type&quot;: &quot;keyword&quot;,
                &quot;fields&quot;: {
                        &quot;pinyin&quot;: {
                                &quot;type&quot;: &quot;text&quot;,
                                &quot;store&quot;: &quot;no&quot;,
                                &quot;term_vector&quot;: &quot;with_offsets&quot;,
                                &quot;analyzer&quot;: &quot;pinyin_analyzer&quot;,
                                &quot;boost&quot;: 10
                        }
                }
        }
}

o-&gt; ik-pinyin
&quot;analysis&quot;: {
        &quot;filter&quot;: {
                &quot;pinyin1&quot;: {
                        &quot;type&quot;: &quot;pinyin&quot;
                }
        },
        &quot;analyzer&quot;: {
                &quot;ik_pinyin_analyzer&quot;: {
                        &quot;filter&quot;: [&quot;pinyin1&quot;,&quot;word_delimiter&quot;],
                        &quot;type&quot;: &quot;custom&quot;,
                        &quot;tokenizer&quot;: &quot;ik_smart&quot;
                }
        }
},
</code></pre>

<h1 id="工具">工具</h1>

<pre><code>kopf
bigdesk
head
    使用
            https://github.com/mobz/elasticsearch-head
            cnpm i
            npm i -g grunt-cli
            grunt server
            curl localhost:9100
    配置
            Gruntfile.js
                    port:9100
</code></pre>

<h1 id="client">client</h1>

<pre><code>olivere/elastic
    Search
            # SearchService
            Do
            Index
            Query
            Sort
            From
            Pretty
    Index
            # IndexService
            Do
            Index
            Type
            Id
            BodyJson
            Refresh
    Suggest
            # SuggestService
    query
            SimpleQueryString
</code></pre>

    </article>

    
<ul class="article-share">
  <li>
    <a href="https://twitter.com/share" class="twitter-share-button">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </li>
  <li>
    <div class="fb-share-button" data-href="http://shenwenqing.com/series/backend/elasticsearch/" data-layout="button_count" data-action="like" data-size="small" data-show-faces="true" data-share="true"></div>
    <div id="fb-root"></div>
    <script>(function(d, s, id) {
      var js, fjs = d.getElementsByTagName(s)[0];
      if (d.getElementById(id)) return;
      js = d.createElement(s); js.id = id;
      js.src = "//connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v2.10";
      fjs.parentNode.insertBefore(js, fjs);
    }(document, 'script', 'facebook-jssdk'));</script>
  </li>
  <li>
    <script src="https://apis.google.com/js/platform.js" async defer></script>
    <g:plus action="share"></g:plus>
  </li>
  <li>
    <a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="basic-label-counter" data-hatena-bookmark-lang="en" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
  </li>
  <li>
    <a data-pocket-label="pocket" data-pocket-count="horizontal" class="pocket-btn" data-lang="en"></a>
    <script>!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script>
  </li>
</ul>


    <ul class="pager article-pager">
      <li class="pager-newer">
          <a href="/series/backend/hadoop/" data-toggle="tooltip" data-placement="top" title="Hadoop">&lt; Newer</a>
      </li>
      <li class="pager-older">
        <a href="/series/backend/lucene/" data-toggle="tooltip" data-placement="top" title="Lucene">Older &gt;</a>
      </li>
    </ul>
  </div>


<div class="site-footer">
  <div class="copyright">&copy; Copyright 2017 outrunJ</div>
  <ul class="site-footer-items">
    <li class="site-footer-item-about"><a href="/about/" title="About">About</a></li>
  </ul>
  <div class="powerdby">
    Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://github.com/taikii/whiteplain">Whiteplain</a>
  </div>
</div>
<script src="/js/script.js"></script>
<script src="/js/custom.js"></script>


</body>
</html>
